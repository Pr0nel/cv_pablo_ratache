{
  "name": "Pablo Ratache Rojas",
  "title": "Data Engineer & Software Developer",
  "portfolioUrl": "linkedin.com/in/pablo-ratache-rojas-9a9602140/ \u2022 pr0nel.github.io/cv_pablo_ratache/",
  "githubProfileUrl": "https://github.com/Pr0nel",
  "about": {
    "summary": "with a background in Physical Engineering, I specialize in building scalable and efficient solutions. With a solid foundation in data warehousing, ETL processes, and programming concepts, I'm eager to contribute to innovative projects and continue to grow professionally. My key skills include Python, SQL, PySpark, and cloud platforms such as Google Cloud and AWS.",
    "professionalProfile": "+1 year of experience designing ETL/ELT pipelines in cloud environments (GCP/AWS), using Apache Airflow, reducing data loading times by 40%. Proven experience developing ML/OCR solutions with 90% accuracy, agile methodologies, quality compliance, web development, and independent projects. Physics Engineering background provides skills in systematic problem decomposition and complex systems modeling for designing scalable data architectures and efficiently solving technical challenges in production environments.",
    "image": "./assets/profile.webp"
  },
  "contact": {
    "email": "pablo.ratache@uni.pe",
    "phone": "+51 966979127"
  },
  "education": [
    {
      "degree": "B.Sc. with a major in Physical Engineering",
      "institution": "Universidad Nacional de Ingenieria \u2022 Rimac - Lima - Peru",
      "dates": "2019",
      "details": "Final project involved simulating energy consumption for heating an Experimental Housing Module located at 4500 masl. The temperature predictions are compared with recorded indoor temperatures to validate the model. The target indoor temperature is then calculated. Finally, the energy required to maintain a neutral indoor temperature is calculated."
    }
  ],
  "publications": [
    {
      "title": "Simulation of Energy Consumption for the Heating of an Experimental Housing Module Located at 4500 masl",
      "journal": "TECNIA",
      "date": "Jun 2021",
      "doiUrl": "https://doi.org/10.21754/tecnia.v21i1.1083"
    }
  ],
  "certifications": [],
  "languages": [
    { "language": "Spanish", "level": "Native", "progress": 100 },
    { "language": "English", "level": "Intermediate", "progress": 50 }
  ],
  "experience": [
    {
      "role": "Jr. Data Engineer",
      "company": "Konexa - WOM \u2022 Chile (Remote) \u2022 Telecom, B2B/B2C",
      "dates": "February 2025 - Present",
      "description": [
        "KEY ACCOMPLISHMENTS:",
        "- Reduced historical data loading times by 40% in Oracle to BigQuery migration through ETL/ELT pipeline automation using Apache Airflow DAG orchestration.",
        "- Migrated historical data from Oracle to BigQuery maintaining 100% data integrity.",
        "- Deployed a Docker container (Linux + PostgreSQL) for web-scraping ETL, normalizing records and reducing latency by 60%.",
        "- Developed modular Machine Learning solution (SAM, CLIP, OCR, AWS Textract) for voucher processing with 90% accuracy.",
        "",
        "RESPONSIBILITIES:",
        "- Documented complete data lineage mapping from Oracle/SandBox/BigQuery sources to final reports, documenting traceability for compliance audits.",
        "- Configured data infrastructure in GCP by defining BigQuery schemas in JSON and Terraform configurations (tfvars), automating deployment through CI/CD in GitLab.",
        "- Delivered final data products, including SQL views, compliance reports, technical documentation, and RFCs using Confluence, with CI/CD in GitLab and tracking in Jira.",
        "- Developed and tested ETL/ELT pipelines on AWS (S3, EC2, PySpark) with Jupyter Notebooks for interactive development and complex SQL to scalable PySpark code translation.",
        "- Orchestrated distributed PySpark jobs on AWS EMR through Apache Airflow DAGs, ensuring scheduled executions, retries, and status monitoring."
      ]
    },
    {
      "role": "Production Researcher | Process Engineer",
      "company": "Productora De Alimentos Uno S.A.C. \u2022 Ate-Lima-Peru \u2022 Food Processing, B2B",
      "dates": "May 2024 - January 2025",
      "description": [
        "- Implemented OEE KPI system alongside Production and Operational Excellence teams, establishing the first operational efficiency measurement.",
        "- Established statistical control methodology with Cp and Cpk indices in coordination with Quality team, creating the first process capability monitoring system.",
        "- Supported operational data loading and structuring in SQL Server for production KPI reporting.",
        "- Performed tank and equipment calibration, ensuring metrological traceability.",
        "- Defined reprocessing limits to optimize fermentation times and reduce waste."
      ]
    },
    {
      "role": "Calibration Assistant",
      "company": "Factio Qualitas S.A.C. \u2022 Surco-Lima-Peru \u2022 Pharmaceutical Consulting, B2B/B2C",
      "dates": "June 2023 - January 2024",
      "description": [
        "- Supervised and mentored a collaborator, reducing ramp-up time by 50% and improving delivery consistency to 80%.",
        "- Implemented centralized client, equipment, and certificate management system with cloud storage and data governance, reducing service time by 60%.",
        "- Applied data-driven approach for results analysis and decision-making.",
        "- Coordinated with external suppliers for field calibration, ensuring technical, regulatory, and schedule compliance.",
        "- Collaborated with QA/QC on continuous improvement of laboratory management system.",
        "- Supported documentation for ISO/IEC 17025 accreditation."
      ]
    }
  ],
  "projects": [
    {
      "title": "Voucher Processing with OCR and Machine Learning",
      "description": "I designed a Python application that processes voucher images (or receipts) through a pipeline that includes segmenting the vouchers within a larger image, validating whether the segments are actually vouchers and extracting text using OCR.",
      "image": "assets/project1.webp",
      "repositoryUrl": "https://github.com/Pr0nel/proyecto_ocr_vouchers"
    },
    {
      "title": "Data Analysis and Modeling for Solar Radiation Prediction",
      "description": "Data analysis and modeling project to predict hourly solar radiation over a given time horizon. This project involves data exploration, data preprocessing and cleaning, and training a machine learning model to perform the prediction.",
      "image": "assets/project2.webp",
      "repositoryUrl": "https://github.com/Pr0nel/weather_data"
    },
    {
      "title": "ETL/ELT Pipeline: Web Data Ingestion and Normalization",
      "description": "I developed an ETL/ELT pipeline for web data ingestion (web scraping), optimizing the extraction and normalization process. I used technologies such as Python and PostgreSQL for data logic and Docker for containerization and deployment in a Linux environment. The project managed to normalize daily logs and reduce processing latency by 60%.",
      "image": "assets/project3.webp",
      "repositoryUrl": "https://github.com/Pr0nel/snippf-poc"
    }
  ],
  "skills": {
    "languages": [
      { "name": "C/C++", "level": 100 },
      { "name": "Python", "level": 90 },
      { "name": "SQL", "level": 90 },
      { "name": "PySpark", "level": 80 },
      { "name": "Bash", "level": 80 },
      { "name": "Java", "level": 70 },
      { "name": "HTML", "level": 65 },
      { "name": "CSS", "level": 65 },
      { "name": "JavaScript", "level": 65 }
    ],
    "tools": [
      {
        "name": "Project management tools: Slack, Microsoft Teams, Trello, Jira, Confluence",
        "level": 100
      },
      {
        "name": "Version control: Git, GitHub, GitLab, Bitbucket",
        "level": 100
      },
      {
        "name": "Cloud, CI/CD & Orchestration: GCP, AWS, Apache Airflow, Terraform (IaC)",
        "level": 80
      },
      {
        "name": "Data analysis & visualization tools: Microsoft Excel, Power BI, Looker Studio",
        "level": 70
      },
      {
        "name": "Operating systems: Linux, Windows",
        "level": 100
      },
      {
        "name": "Containers & virtualization: Docker, Docker Compose, VirtualBox",
        "level": 80
      },
      {
        "name": "Database: PostgreSQL (OLTP), BigQuery (OLAP)",
        "level": 100
      }
    ],
    "concepts": [
      { "name": "Fast learner", "level": 100 },
      { "name": "Strategic planning", "level": 100 },
      { "name": "Team player", "level": 100 },
      { "name": "Adaptability", "level": 100 },
      { "name": "Pragmatic thinking", "level": 100 },
      { "name": "Abstract thinking", "level": 100 },
      { "name": "Active listening", "level": 100 },
      { "name": "Problem solving", "level": 100 },
      { "name": "Time management", "level": 100 },
      { "name": "Change management", "level": 100 },
      { "name": "Project management and agile methodologies: Scrum, Kanban, Design Thinking, Lean mindset, PMBOK", "level": 100 },
      { "name": "Quality & efficiency metrics: OEE, Cp, Cpk", "level": 100 },
      { "name": "QA/QC & Regulations: ISO/IEC 17025, INACAL", "level": 100 },
      { "name": "Data Warehousing", "level": 100 },
      { "name": "ETL Processes", "level": 100 },
      { "name": "Data Modeling", "level": 100 },
      { "name": "Analytics & Big Data", "level": 100 },
      { "name": "Cloud Computing (AWS/GCP)", "level": 80 },
      { "name": "Machine Learning & Computer Vision: CLIP, SAM, AWS Textract, OCR", "level": 80 }
    ]
  }
}
